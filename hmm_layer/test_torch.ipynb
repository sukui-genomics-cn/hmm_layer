{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def fill_triangular(x, upper=False, name=None):\n",
    "    \"\"\"Creates a (batch of) triangular matrix from a vector of inputs.\n",
    "\n",
    "    Args:\n",
    "        x: `Tensor` representing lower (or upper) triangular elements.\n",
    "        upper: Python `bool` representing whether output matrix should be upper\n",
    "          triangular (`True`) or lower triangular (`False`, default).\n",
    "        name: Python `str`. The name to give this op (not used in PyTorch version).\n",
    "\n",
    "    Returns:\n",
    "        tril: `Tensor` with lower (or upper) triangular elements filled from `x`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if `x` cannot be mapped to a triangular matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the last dimension size (m)\n",
    "    m = x.shape[-1]\n",
    "\n",
    "    # Calculate n from m using the quadratic formula\n",
    "    if m is not None:\n",
    "        m = int(m)\n",
    "        n = int(np.sqrt(0.25 + 2. * m) - 0.5)\n",
    "        if n != np.floor(n):\n",
    "            raise ValueError(f\"Input right-most shape ({m}) does not correspond to a triangular matrix.\")\n",
    "    else:\n",
    "        m = x.shape[-1]\n",
    "        n = int(torch.sqrt(0.25 + 2. * m).item() - 0.5)\n",
    "\n",
    "    # Get the batch shape of x (excluding the last dimension)\n",
    "    batch_shape = x.shape[:-1]\n",
    "\n",
    "    # Create the new shape for the output tensor (batch dimensions, n x n)\n",
    "    new_shape = batch_shape + (n, n)\n",
    "\n",
    "    # Reshape x to the new shape\n",
    "    x = x.view(-1, m)  # Flatten the last dimension to make it 2D for reshaping\n",
    "    if upper:\n",
    "        # Upper triangular: first part is x, the second part is the reverse of the last elements\n",
    "        x_list = [x, torch.flip(x[..., n:], dims=[-1])]\n",
    "    else:\n",
    "        # Lower triangular: first part is reversed x, the second part is x\n",
    "        x_list = [x[..., n:], torch.flip(x, dims=[-1])]\n",
    "\n",
    "    x = torch.cat(x_list, dim=-1).view(*new_shape)\n",
    "\n",
    "    # Create a triangular matrix using torch.tril or torch.triu\n",
    "    if upper:\n",
    "        x = torch.triu(x, diagonal=0)  # Keep the upper triangular part\n",
    "    else:\n",
    "        x = torch.tril(x, diagonal=0)  # Keep the lower triangular part\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_triangular(x, upper=False):\n",
    "    \"\"\"\n",
    "    从输入向量创建一个 (批量的) 三角矩阵。\n",
    "\n",
    "    参数:\n",
    "        x: `Tensor`, 表示下三角 (或上三角) 元素。\n",
    "        upper: Python `bool`, 表示输出矩阵是否应为上三角矩阵 (`True`) 或下三角矩阵 (`False`, 默认) 。\n",
    "\n",
    "    返回:\n",
    "        tril: `Tensor`, 填充了从 `x` 中提取的下三角 (或上三角) 元素的矩阵。\n",
    "\n",
    "    异常:\n",
    "        ValueError: 如果 `x` 无法映射到三角矩阵。\n",
    "    \"\"\"\n",
    "    # 将输入转换为 PyTorch 张量\n",
    "    x = torch.as_tensor(x)\n",
    "\n",
    "    # 获取输入张量的最后一个维度大小 (m) \n",
    "    m = x.shape[-1]\n",
    "\n",
    "    # 通过二次公式计算矩阵的维度 n\n",
    "    # 公式 : n * (n + 1) / 2 = m\n",
    "    n = int((math.sqrt(8 * m + 1) - 1) / 2)\n",
    "    if n * (n + 1) // 2 != m:\n",
    "        raise ValueError(f'输入的最右侧维度大小 ({m}) 无法对应一个三角矩阵。')\n",
    "\n",
    "    # 初始化输出矩阵, 形状为 [..., n, n], 填充为 0\n",
    "    output_shape = list(x.shape[:-1]) + [n, n]\n",
    "    matrix = torch.zeros(output_shape, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    # 使用三角矩阵的索引填充矩阵\n",
    "    if upper:\n",
    "        # 如果是上三角矩阵, 填充上三角部分\n",
    "        # 使用 torch.triu_indices 生成上三角的索引\n",
    "        row_indices, col_indices = torch.triu_indices(n, n)\n",
    "        matrix[..., row_indices, col_indices] = x\n",
    "    else:\n",
    "        # 如果是下三角矩阵, 填充下三角部分\n",
    "        # 使用 torch.tril_indices 生成下三角的索引\n",
    "        row_indices, col_indices = torch.tril_indices(n, n)\n",
    "        matrix[..., row_indices, col_indices] = x\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def fill_triangular_inverse(x, upper=False):\n",
    "    \"\"\"\n",
    "    将 (批量的) 三角矩阵转换为向量。\n",
    "\n",
    "    参数 : \n",
    "        x: 表示下三角或上三角元素的张量。\n",
    "        upper: 布尔值, 表示输出矩阵是否为上三角矩阵 (True) 或下三角矩阵 (False, 默认) 。\n",
    "\n",
    "    返回 : \n",
    "        flat_tril: 表示从 x 中向量化的下三角或上三角元素的向量形张量。\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取最后一个维度的大小 (n)\n",
    "    n = x.shape[-1]\n",
    "    # 计算向量的长度 (m)\n",
    "    m = (n * (n + 1)) // 2\n",
    "    # 获取张量的维度数量\n",
    "    ndims = len(x.shape)\n",
    "\n",
    "    if upper:\n",
    "        # 如果是上三角矩阵\n",
    "        initial_elements = x[..., 0, :]  # 获取第一行元素\n",
    "        triangular_portion = x[..., 1:, :]  # 获取剩余的三角部分\n",
    "    else:\n",
    "        # 如果是下三角矩阵\n",
    "        initial_elements = torch.flip(x[..., -1, :], dims=[ndims - 2])  # 获取最后一行并反转\n",
    "        triangular_portion = x[..., :-1, :]  # 获取剩余的三角部分\n",
    "\n",
    "    # 反转三角部分并相加\n",
    "    rotated_triangular_portion = torch.flip(torch.flip(triangular_portion, dims=[ndims - 1]), dims=[ndims - 2])\n",
    "    consolidated_matrix = triangular_portion + rotated_triangular_portion\n",
    "\n",
    "    # 重塑三角部分并连接初始元素\n",
    "    end_sequence = torch.reshape(consolidated_matrix, x.shape[:-2] + (n * (n - 1),))\n",
    "    y = torch.cat([initial_elements, end_sequence[..., :m - n]], dim=-1)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def make_k_mers(sequences, k, pivot_left=True):\n",
    "    \"\"\"\n",
    "    将 one-hot 编码的核苷酸序列映射到 k-mer 表示。\n",
    "\n",
    "    参数 : \n",
    "        sequences: 形状为 (b, L, 5) 的张量, 表示长度为 L 的序列。\n",
    "                   假定最后一个维度是 one-hot 编码, 其中 \"N\" 对应于最后一个位置。\n",
    "        k: 指定 k-mer 长度的整数。\n",
    "        pivot_left: 指定是否将 k-mer 旋转到左侧或右侧的布尔值。\n",
    "\n",
    "    返回 : \n",
    "        形状为 (b, L, 4**k-1, 4) 的张量。如果 pivot_left 为 True, \n",
    "        则最后一个维度对应于 k-mer 最左侧位置的 4 个可能的核苷酸。\n",
    "        否则, 最后一个维度对应于 k-mer 最右侧的位置。\n",
    "        如果 k-mer 包含 N, 则在可能位于该位置的 4 个常规核苷酸中等概率表示。\n",
    "    \"\"\"\n",
    "    L = sequences.shape[-2]\n",
    "    n = sequences.shape[-1] - 1  # 字母表大小是字符数减 1 (N)\n",
    "    n = torch.tensor(n, dtype=sequences.dtype)\n",
    "    # 在 N 的情况下, 在字母表上均匀分布\n",
    "    sequences_no_N = sequences[..., :-1]\n",
    "    N_pos = (sequences[..., -1:] == 1).to(sequences.dtype)\n",
    "    sequences_no_N += (1 / n) * N_pos\n",
    "    # 计算跨越序列边界的 k-mer 的填充\n",
    "    pad = torch.ones_like(sequences_no_N[:, :k - 1, :], dtype=sequences.dtype) / n\n",
    "    if pivot_left:\n",
    "        sequences_padded_no_N = torch.cat([sequences_no_N, pad], dim=-2)\n",
    "        k_mers = sequences_padded_no_N[:, :L, None, :]\n",
    "    else:\n",
    "        sequences_padded_no_N = torch.cat([pad, sequences_no_N], dim=-2)\n",
    "        k_mers = sequences_padded_no_N[:, k - 1:L + k - 1, None, :]\n",
    "    if pivot_left:\n",
    "        iteration_range = range(1, k)\n",
    "    else:\n",
    "        iteration_range = range(k - 2, -1, -1)\n",
    "\n",
    "    for i in iteration_range:\n",
    "        shift_i = sequences_padded_no_N[:, i:L + i, None, :, None]\n",
    "        k_mers = k_mers[..., None, :] * shift_i\n",
    "        if pivot_left:\n",
    "            shape = [4**i, 4]\n",
    "        else:\n",
    "            shape = [4**(k - i - 1), 4]\n",
    "        k_mers = k_mers.reshape(list(k_mers.shape[:-3]) + shape)\n",
    "    return k_mers\n",
    "\n",
    "def encode_kmer_string(kmer, pivot_left=True, alphabet=\"ACGT\"):\n",
    "    \"\"\"\n",
    "    将 k-mer 转换为格式为 (i, j) 的类, 其中 i < n^{k-1} 且 j < n, 其中 n 是字母表大小。\n",
    "    例如, AAA -> (0, 0), AAT -> (3, 0), TAA -> (0, 3) 如果 pivot_left 为 True, 否则\n",
    "        AAA -> (0, 0), AAT -> (0, 3), TAA -> (12, 0)\n",
    "    输出是 A、C、G、T 情况下的这些类的 one-hot 编码。\n",
    "    如果 k-mer 包含 N, 则在 4 个常规核苷酸中等概率表示。\n",
    "    \"\"\"\n",
    "    alphabet_with_unknown = alphabet + \"N\"\n",
    "    kmer = [alphabet_with_unknown.index(x) for x in kmer]\n",
    "    kmer = torch.tensor(kmer)\n",
    "    one_hot = torch.nn.functional.one_hot(kmer, num_classes=len(alphabet_with_unknown)).to(torch.float32) #修正了这一行\n",
    "    encoded_kmers = make_k_mers(one_hot.unsqueeze(0), k=len(kmer), pivot_left=pivot_left)\n",
    "    if pivot_left:\n",
    "        return encoded_kmers.squeeze(0)[0]\n",
    "    else:\n",
    "        return encoded_kmers.squeeze(0)[-1]\n",
    "\n",
    "# 测试用例\n",
    "sequences = torch.tensor([[[1, 0, 0, 0, 0],\n",
    "                        [0, 1, 0, 0, 0],\n",
    "                        [0, 0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1, 0],\n",
    "                        [0, 0, 0, 0, 1]]], dtype=torch.float32)\n",
    "k = 3\n",
    "\n",
    "k_mers_left = make_k_mers(sequences, k, pivot_left=True)\n",
    "k_mers_right = make_k_mers(sequences, k, pivot_left=False)\n",
    "\n",
    "print(\"k_mers_left shape:\", k_mers_left.shape)\n",
    "print(\"k_mers_right shape:\", k_mers_right.shape)\n",
    "\n",
    "kmer_string = \"ACGN\"\n",
    "encoded_kmer_left = encode_kmer_string(kmer_string, pivot_left=True)\n",
    "encoded_kmer_right = encode_kmer_string(kmer_string, pivot_left=False)\n",
    "\n",
    "print(\"encoded_kmer_left shape:\", encoded_kmer_left.shape)\n",
    "print(\"encoded_kmer_right shape:\", encoded_kmer_right.shape)\n",
    "\n",
    "print(\"k_mers_left:\", k_mers_left)\n",
    "print(\"k_mers_right:\", k_mers_right)\n",
    "print(\"encoded_kmer_left:\", encoded_kmer_left)\n",
    "print(\"encoded_kmer_right:\", encoded_kmer_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inverse_softplus(features):\n",
    "    \"\"\"\n",
    "    计算 softplus 函数的逆函数。\n",
    "\n",
    "    参数 : \n",
    "        features: 输入张量。\n",
    "\n",
    "    返回 : \n",
    "        softplus 函数的逆函数的结果张量。\n",
    "    \"\"\"\n",
    "    # 转换为 float64 以防止大条目的溢出\n",
    "    features64 = features.double()\n",
    "    result = torch.log(torch.expm1(features64))\n",
    "    # 转换回 `features` 的原始数据类型\n",
    "    return result.to(features.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seqmamba2_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
