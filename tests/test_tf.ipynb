{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower Triangular Matrix:\n",
      "tf.Tensor(\n",
      "[[4. 0. 0.]\n",
      " [6. 5. 0.]\n",
      " [3. 2. 1.]], shape=(3, 3), dtype=float32)\n",
      "\n",
      "Upper Triangular Matrix:\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [0. 5. 6.]\n",
      " [0. 0. 4.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fill_triangular(x, upper=False, name=None):\n",
    "    \"\"\"Creates a (batch of) triangular matrix from a vector of inputs.\n",
    "\n",
    "    Args:\n",
    "        x: `Tensor` representing lower (or upper) triangular elements.\n",
    "        upper: Python `bool` representing whether output matrix should be upper\n",
    "          triangular (`True`) or lower triangular (`False`, default).\n",
    "        name: Python `str`. The name to give this op.\n",
    "\n",
    "    Returns:\n",
    "        tril: `Tensor` with lower (or upper) triangular elements filled from `x`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if `x` cannot be mapped to a triangular matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name or 'fill_triangular'):\n",
    "        x = tf.convert_to_tensor(x, name='x')\n",
    "\n",
    "        # Get the last dimension size (m)\n",
    "        m = x.shape[-1]\n",
    "        \n",
    "        # Calculate n from m using the quadratic formula\n",
    "        if m is not None:\n",
    "            m = np.int32(m)\n",
    "            n = np.sqrt(0.25 + 2. * m) - 0.5\n",
    "            if n != np.floor(n):\n",
    "                raise ValueError('Input right-most shape ({}) does not '\n",
    "                                 'correspond to a triangular matrix.'.format(m))\n",
    "            n = np.int32(n)\n",
    "            static_final_shape = tf.TensorShape(x.shape[:-1]).concatenate([n, n])\n",
    "        else:\n",
    "            m = tf.shape(x)[-1]\n",
    "            n = tf.cast(\n",
    "                tf.sqrt(0.25 + tf.cast(2 * m, dtype=tf.float32)), dtype=tf.int32)\n",
    "            static_final_shape = tf.TensorShape(x.shape[:-1]).concatenate([None, None])\n",
    "\n",
    "        # Determine the shape of the output tensor\n",
    "        ndims = tf.rank(x)\n",
    "        if upper:\n",
    "            x_list = [x, tf.reverse(x[..., n:], axis=[ndims - 1])]\n",
    "        else:\n",
    "            x_list = [x[..., n:], tf.reverse(x, axis=[ndims - 1])]\n",
    "        \n",
    "        new_shape = (\n",
    "            static_final_shape.as_list()\n",
    "            if static_final_shape.is_fully_defined() else tf.concat(\n",
    "                [tf.shape(x)[:-1], [n, n]], axis=0))\n",
    "        \n",
    "        x = tf.reshape(tf.concat(x_list, axis=-1), new_shape)\n",
    "        \n",
    "        # Create a triangular matrix\n",
    "        x = tf.linalg.band_part(\n",
    "            x, num_lower=(0 if upper else -1), num_upper=(-1 if upper else 0))\n",
    "        \n",
    "        # Set the static shape if it is fully defined\n",
    "        x.set_shape(static_final_shape)\n",
    "        return x\n",
    "\n",
    "# 输入向量\n",
    "x_lower = tf.constant([1.0, 2.0, 3.0, \n",
    "                       .0, 5.0, 6.0], dtype=tf.float32)\n",
    "x_upper = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], dtype=tf.float32)\n",
    "\n",
    "# 测试生成下三角矩阵\n",
    "lower_triangular_matrix = fill_triangular(x_lower, upper=False, name=\"fill_triangular_lower\")\n",
    "print(\"Lower Triangular Matrix:\")\n",
    "print(lower_triangular_matrix)\n",
    "\n",
    "# 测试生成上三角矩阵\n",
    "upper_triangular_matrix = fill_triangular(x_upper, upper=True, name=\"fill_triangular_upper\")\n",
    "print(\"\\nUpper Triangular Matrix:\")\n",
    "print(upper_triangular_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_triangular_inverse(x, upper=False, name=None):\n",
    "    \"\"\"Creates a vector from a (batch of) triangular matrix.\n",
    "\n",
    "    Args:\n",
    "        x: `Tensor` representing lower (or upper) triangular elements.\n",
    "        upper: Python `bool` representing whether output matrix should be upper\n",
    "          triangular (`True`) or lower triangular (`False`, default).\n",
    "        name: Python `str`. The name to give this op.\n",
    "\n",
    "    Returns:\n",
    "        flat_tril: (Batch of) vector-shaped `Tensor` representing vectorized lower\n",
    "          (or upper) triangular elements from `x`.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name or 'fill_triangular_inverse'):\n",
    "        x = tf.convert_to_tensor(x, name='x')\n",
    "        \n",
    "        # Get the last dimension size (n)\n",
    "        n = x.shape[-1]\n",
    "        \n",
    "        if n is not None:\n",
    "            n = np.int32(n)\n",
    "            m = np.int32((n * (n + 1)) // 2)\n",
    "            static_final_shape = tf.TensorShape(x.shape[:-2]).concatenate([m])\n",
    "        else:\n",
    "            n = tf.shape(x)[-1]\n",
    "            m = (n * (n + 1)) // 2\n",
    "            static_final_shape = tf.TensorShape(x.shape[:-2]).concatenate([None])\n",
    "        \n",
    "        ndims = tf.rank(x)\n",
    "        if upper:\n",
    "            initial_elements = x[..., 0, :]\n",
    "            triangular_portion = x[..., 1:, :]\n",
    "        else:\n",
    "            initial_elements = tf.reverse(x[..., -1, :], axis=[ndims - 2])\n",
    "            triangular_portion = x[..., :-1, :]\n",
    "\n",
    "        rotated_triangular_portion = tf.reverse(\n",
    "            tf.reverse(triangular_portion, axis=[ndims - 1]), axis=[ndims - 2])\n",
    "        \n",
    "        consolidated_matrix = triangular_portion + rotated_triangular_portion\n",
    "        \n",
    "        end_sequence = tf.reshape(\n",
    "            consolidated_matrix,\n",
    "            tf.concat([tf.shape(x)[:-2], [n * (n - 1)]], axis=0))\n",
    "        \n",
    "        y = tf.concat([initial_elements, end_sequence[..., :m - n]], axis=-1)\n",
    "        \n",
    "        y.set_shape(static_final_shape)\n",
    "        return y\n",
    "\n",
    "# 输入向量\n",
    "x_lower = tf.constant([1.0, 2.0, 3.0, \n",
    "                       .0, 5.0, 6.0], dtype=tf.float32)\n",
    "x_upper = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], dtype=tf.float32)\n",
    "\n",
    "# 测试生成下三角矩阵\n",
    "lower_triangular_matrix = fill_triangular(x_lower, upper=False, name=\"fill_triangular_lower\")\n",
    "print(\"Lower Triangular Matrix:\")\n",
    "print(lower_triangular_matrix)\n",
    "\n",
    "# 测试生成上三角矩阵\n",
    "upper_triangular_matrix = fill_triangular(x_upper, upper=True, name=\"fill_triangular_upper\")\n",
    "print(\"\\nUpper Triangular Matrix:\")\n",
    "print(upper_triangular_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_mers_left shape: (1, 5, 16, 4)\n",
      "k_mers_right shape: (1, 5, 16, 4)\n",
      "encoded_kmer_left shape: (64, 4)\n",
      "encoded_kmer_right shape: (64, 4)\n",
      "k_mers_left: tf.Tensor(\n",
      "[[[[0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [1.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]]\n",
      "\n",
      "  [[0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       1.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]]\n",
      "\n",
      "  [[0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.       0.      ]\n",
      "   [0.       0.       0.25     0.      ]\n",
      "   [0.       0.       0.25     0.      ]\n",
      "   [0.       0.       0.25     0.      ]\n",
      "   [0.       0.       0.25     0.      ]]\n",
      "\n",
      "  [[0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]\n",
      "   [0.       0.       0.       0.0625  ]]\n",
      "\n",
      "  [[0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]\n",
      "   [0.015625 0.015625 0.015625 0.015625]]]], shape=(1, 5, 16, 4), dtype=float32)\n",
      "k_mers_right: tf.Tensor(\n",
      "[[[[0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]\n",
      "   [0.0625 0.     0.     0.    ]]\n",
      "\n",
      "  [[0.     0.25   0.     0.    ]\n",
      "   [0.     0.25   0.     0.    ]\n",
      "   [0.     0.25   0.     0.    ]\n",
      "   [0.     0.25   0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]]\n",
      "\n",
      "  [[0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     1.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]]\n",
      "\n",
      "  [[0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     1.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]]\n",
      "\n",
      "  [[0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.     0.     0.     0.    ]\n",
      "   [0.25   0.25   0.25   0.25  ]\n",
      "   [0.     0.     0.     0.    ]]]], shape=(1, 5, 16, 4), dtype=float32)\n",
      "encoded_kmer_left: tf.Tensor(\n",
      "[[0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]], shape=(64, 4), dtype=float32)\n",
      "encoded_kmer_right: tf.Tensor(\n",
      "[[0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.  ]], shape=(64, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_k_mers(sequences, k, pivot_left=True):\n",
    "    \"\"\" Maps one hot encoded nucleotide sequences to a k-mer representation. \n",
    "        Args:\n",
    "            sequences: A tensor of shape (b, L, 5) representing sequences of length L. \n",
    "                        Assumes that the last dimension is one-hot encoded with \"N\" corresponding to the last position.\n",
    "            k: An integer specifying the length of the k-mer\n",
    "            pivot_left: A boolean specifying whether to pivot the k-mer to the left or right. \n",
    "        Returns:\n",
    "            A tensor of shape (b, L, 4**k-1, 4). If pivot_left is True, the last dimension corresponds \n",
    "            to the 4 possible nucleotides in the leftmost position of the k-mer. \n",
    "            Otherwise, the last dimension corresponds to the rightmost position in the k-mer.\n",
    "            If the k-mer contains N, this is expressed equiprobably among the regular 4 nucleotides possible\n",
    "            at that position.\n",
    "    \"\"\"\n",
    "    L = tf.shape(sequences)[-2]\n",
    "    n = tf.shape(sequences)[-1]-1 #alphabet size is the number of characters minus 1 (N)\n",
    "    n = tf.cast(n, dtype=sequences.dtype) \n",
    "    # uniform distribution over alphabet in case of N \n",
    "    sequences_no_N = sequences[..., :-1]\n",
    "    N_pos = tf.cast(sequences[..., -1:] == 1, dtype=sequences.dtype)\n",
    "    sequences_no_N += (1/n) * N_pos\n",
    "    # compute a padding for kmers that range over the sequence boundaries\n",
    "    pad = tf.ones_like(sequences_no_N[:, :k-1, :], dtype=sequences.dtype) / n\n",
    "    if pivot_left:\n",
    "        sequences_padded_no_N = tf.concat([sequences_no_N, pad], axis=-2)\n",
    "        k_mers = sequences_padded_no_N[:, :L, tf.newaxis, :] \n",
    "    else:\n",
    "        sequences_padded_no_N = tf.concat([pad, sequences_no_N], axis=-2)\n",
    "        k_mers = sequences_padded_no_N[:, k-1:L+k-1, tf.newaxis, :] \n",
    "    for i in range(1, k) if pivot_left else range(k-2, -1, -1):\n",
    "        shift_i = sequences_padded_no_N[:, i:L+i, tf.newaxis, :, tf.newaxis] \n",
    "        k_mers = k_mers[..., tf.newaxis, :] * shift_i\n",
    "        shape = [4**i, 4] if pivot_left else [4**(k-i-1), 4]\n",
    "        k_mers = tf.reshape(k_mers, tf.concat([tf.shape(k_mers)[:-3], shape], axis=0))\n",
    "    return k_mers\n",
    "\n",
    "\n",
    "\n",
    "def encode_kmer_string(kmer, pivot_left=True, alphabet=\"ACGT\"):\n",
    "    \"\"\" Converts a k-mer to classes in the format (i,j) with i < n^{k-1} and j < n where n is the alphabet size. \n",
    "        E.g. AAA -> (0,0), AAT -> (3,0), TAA -> (0,3) if pivot_left is True, otherwise\n",
    "             AAA -> (0,0), AAT -> (0,3), TAA -> (12, 0)\n",
    "        The output is a one-hot encoding of these classes in case of A,C,G,T. \n",
    "        If the k-mer contains N, this is expressed equiprobably among the regular 4 nucleotides.\n",
    "    \"\"\"\n",
    "    alphabet_with_unknown = alphabet + \"N\"\n",
    "    kmer = [alphabet_with_unknown.index(x) for x in kmer]\n",
    "    kmer = tf.constant(kmer)\n",
    "    one_hot = tf.one_hot(kmer, len(alphabet_with_unknown)) \n",
    "    encoded_kmers = make_k_mers(one_hot[tf.newaxis, ...], k=len(kmer), pivot_left=pivot_left)\n",
    "    if pivot_left:\n",
    "        return tf.squeeze(encoded_kmers)[0]\n",
    "    else:\n",
    "        return tf.squeeze(encoded_kmers)[-1]\n",
    "    \n",
    "    \n",
    "# 测试用例\n",
    "sequences = tf.constant([[[1, 0, 0, 0, 0],\n",
    "                        [0, 1, 0, 0, 0],\n",
    "                        [0, 0, 1, 0, 0],\n",
    "                        [0, 0, 0, 1, 0],\n",
    "                        [0, 0, 0, 0, 1]]], dtype=tf.float32)\n",
    "k = 3\n",
    "\n",
    "k_mers_left = make_k_mers(sequences, k, pivot_left=True)\n",
    "k_mers_right = make_k_mers(sequences, k, pivot_left=False)\n",
    "\n",
    "print(\"k_mers_left shape:\", k_mers_left.shape)\n",
    "print(\"k_mers_right shape:\", k_mers_right.shape)\n",
    "\n",
    "kmer_string = \"ACGN\"\n",
    "encoded_kmer_left = encode_kmer_string(kmer_string, pivot_left=True)\n",
    "encoded_kmer_right = encode_kmer_string(kmer_string, pivot_left=False)\n",
    "\n",
    "print(\"encoded_kmer_left shape:\", encoded_kmer_left.shape)\n",
    "print(\"encoded_kmer_right shape:\", encoded_kmer_right.shape)\n",
    "\n",
    "print(\"k_mers_left:\", k_mers_left)\n",
    "print(\"k_mers_right:\", k_mers_right)\n",
    "print(\"encoded_kmer_left:\", encoded_kmer_left)\n",
    "print(\"encoded_kmer_right:\", encoded_kmer_right)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiberius_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
